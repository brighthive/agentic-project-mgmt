[
  {
    "key": "BH-166",
    "summary": "Define Rich Connector Metadata Spec",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Standardize metadata format for connectors to push rich context to Neo4j (asset, schema, lineage, quality, governance)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design connector metadata JSON schema (OpenAPI spec). Define sections: asset (name, type, location), schema (columns, types), lineage (upstream, transformation), quality (metrics), governance (classification, owner). Create GraphQL mutation spec (createDataAssetWithContext). Write connector developer guide outline."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of enhanced connectors (Sprint 2). Connector SDK/library. Connector testing framework."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Connector metadata JSON schema (OpenAPI 3.0 spec) with 5 sections: asset, schema, lineage, quality, governance"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 GraphQL mutation spec: createDataAssetWithContext(input: DataAssetContextInput) returns DataAsset"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Example payloads: Glue Crawler, DBT, custom connector"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Validation rules: required fields (name, type, location), optional fields (quality, lineage)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Versioning strategy: schema version in payload (v1, v2, etc.)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Backward compatibility: existing createDataAsset mutation still works"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Solutions Architect, Technical Writer"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Connector metadata JSON schema:**\n```json\n{\n  \"version\": \"v1\",\n  \"asset\": {\n    \"name\": \"customers\",\n    \"type\": \"table\",  // or \"view\", \"materialized_view\", \"file\", \"stream\"\n    \"location\": \"s3://org-a-raw/customers.parquet\",\n    \"format\": \"parquet\",  // or \"csv\", \"json\", \"avro\", \"delta\"\n    \"row_count\": 1000000,\n    \"size_bytes\": 52428800,\n    \"created_at\": \"2026-01-10T10:00:00Z\",\n    \"updated_at\": \"2026-01-12T08:00:00Z\"\n  },\n  \"schema\": {\n    \"version\": \"v2.3\",\n    \"hash\": \"abc123def456\",  // MD5 of columns JSON\n    \"columns\": [\n      {\n        \"name\": \"customer_id\",\n        \"type\": \"INTEGER\",\n        \"nullable\": false,\n        \"primary_key\": true,\n        \"description\": \"Unique customer identifier\"\n      },\n      {\n        \"name\": \"email\",\n        \"type\": \"VARCHAR(255)\",\n        \"nullable\": true,\n        \"description\": \"Customer email address\"\n      },\n      {\n        \"name\": \"created_at\",\n        \"type\": \"TIMESTAMP\",\n        \"nullable\": false,\n        \"description\": \"Record creation timestamp\"\n      }\n    ]\n  },\n  \"lineage\": {\n    \"upstream\": [\n      {\n        \"type\": \"s3_file\",\n        \"location\": \"s3://org-a-raw/customers.csv\",\n        \"last_modified\": \"2026-01-12T07:00:00Z\"\n      },\n      {\n        \"type\": \"api\",\n        \"source\": \"salesforce_api\",\n        \"endpoint\": \"https://api.salesforce.com/v1/customers\"\n      }\n    ],\n    \"transformation\": {\n      \"type\": \"glue_crawler\",  // or \"dbt_model\", \"redshift_view\", \"lambda_etl\"\n      \"job_id\": \"crawler-abc-123\",\n      \"logic\": \"Discovered schema from parquet file\",\n      \"config\": {\n        \"crawler_name\": \"org-a-raw-crawler\",\n        \"database\": \"org_a\"\n      }\n    }\n  },\n  \"quality\": {\n    \"completeness\": 0.92,\n    \"accuracy\": 0.95,\n    \"null_counts\": {\n      \"email\": 50000\n    },\n    \"duplicates\": 10,\n    \"last_checked\": \"2026-01-12T08:00:00Z\"\n  },\n  \"governance\": {\n    \"data_classification\": \"PII\",  // Public, Internal, Confidential, PII\n    \"compliance_tags\": [\"GDPR\", \"HIPAA\"],\n    \"business_owner\": \"jane@acme.com\",\n    \"technical_steward\": \"john@acme.com\",\n    \"business_purpose\": \"Customer master data for CRM\",\n    \"retention_days\": 365\n  }\n}\n```\n\n**GraphQL mutation spec:**\n```graphql\nmutation createDataAssetWithContext(\n  $input: DataAssetContextInput!\n) {\n  createDataAssetWithContext(input: $input) {\n    uuid\n    name\n    business_purpose\n    quality_score\n    schema_version\n    lineage_summary {\n      upstream_count\n      downstream_count\n    }\n  }\n}\n\ninput DataAssetContextInput {\n  version: String!  # \"v1\"\n  organization_id: ID!\n  workspace_id: ID!\n  asset: AssetInput!\n  schema: SchemaInput\n  lineage: LineageInput\n  quality: QualityInput\n  governance: GovernanceInput\n}\n```\n\n**Implementation:**\n- File: `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/resolvers/data-asset-resolver.ts`\n- New mutation: `createDataAssetWithContext`\n- Logic:\n  1. Validate input (required fields, types)\n  2. Create DataAsset node\n  3. Create SchemaVersion node (if provided)\n  4. Create lineage edges (if provided)\n  5. Store quality metrics in DynamoDB (if provided)\n  6. Create governance relationships (if provided)\n\n**Versioning:**\n- Version field in payload: \"v1\", \"v2\", etc.\n- Backward compatibility: v1 supports minimal fields, v2 adds new fields\n- Validation: reject unknown versions\n\n**Connector developer guide outline:**\n1. Architecture overview\n2. Metadata specification (JSON schema above)\n3. Authentication (Cognito JWT)\n4. Example implementations (Glue, DBT, custom)\n5. Testing guide\n6. Troubleshooting"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Standardized connector spec enables third-party integrations, reduces connector development time, and ensures consistent metadata quality across all data sources."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:24.880-0600",
    "updated": "2026-01-15T09:59:11.760-0600",
    "priority": "High",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-163",
    "summary": "Design Lineage Visualization",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design interactive lineage visualization showing upstream/downstream dependencies with transformation details."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Create lineage UI mockup (interactive graph). Choose graph rendering library (D3.js, Cytoscape.js, vis.js). Design GraphQL lineage API (upstream, downstream, impact analysis). Document interaction patterns (click, hover, expand)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of lineage visualization (Sprint 2). Column-level lineage visualization. Real-time lineage updates."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Frontend"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Lineage UI mockup created: interactive graph showing data flow (S3 \u2192 Glue \u2192 Redshift \u2192 DBT \u2192 Dashboard)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Graph rendering library chosen: D3.js (most flexible), Cytoscape.js (graph-focused), or vis.js (simple) with justification"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 GraphQL lineage API designed: getLineage(asset_id, direction: upstream/downstream/both, depth: 1-5)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Interaction patterns: click node (expand), hover (show details), double-click (navigate to asset detail)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Features: filter by lineage type (data flow, transformation, usage), highlight impacted assets (what breaks if this changes)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Performance consideration: lazy loading for large graphs (>100 nodes)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: UX Designer, Frontend Engineer"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Library comparison:**\n\n**D3.js:**\n- Pros: Most flexible, full control over rendering, large community\n- Cons: Steep learning curve, requires custom graph layout algorithms\n- Best for: Complex, custom visualizations\n\n**Cytoscape.js:**\n- Pros: Graph-focused, built-in layouts (dagre, cola), good performance\n- Cons: Less flexible than D3, heavier library\n- Best for: Standard graph visualizations, automatic layouts\n\n**vis.js:**\n- Pros: Simple API, quick to implement, built-in physics simulation\n- Cons: Less customization, performance issues with large graphs (>500 nodes)\n- Best for: Prototyping, simple lineage graphs\n\n**Recommendation: Cytoscape.js**\n- Built-in dagre layout (directed acyclic graph) perfect for lineage\n- Good performance up to 1000 nodes\n- Easier to implement than D3, more flexible than vis.js\n\n**Lineage visualization mockup:**\n```\n[S3: raw_customers.csv]\n     \u2193 (Glue Crawler)\n[Glue: org_a.customers]\n     \u2193 (Redshift Spectrum)\n[Redshift: org_a.customers]\n     \u2193 (DBT model: customer_enrichment.sql)\n[DBT: customer_enrichment] \u2190 [S3: raw_addresses.parquet]\n     \u2193 (Visualization)\n[Dashboard: Sales by Region]\n```\n\n**Interaction patterns:**\n- **Click node**: Expand upstream/downstream (1 level)\n- **Hover node**: Show tooltip (transformation type, row count, last_updated)\n- **Double-click node**: Navigate to asset detail page\n- **Hover edge**: Show transformation logic (SQL query, Glue job config)\n- **Right-click node**: Context menu (view lineage, view schema, view quality)\n\n**GraphQL lineage API:**\n```graphql\nquery getLineage(\n  $asset_id: ID!,\n  $direction: LineageDirection!,  # upstream, downstream, both\n  $depth: Int!  # 1-5 levels\n) {\n  lineage(asset_id: $asset_id, direction: $direction, depth: $depth) {\n    nodes {\n      uuid\n      name\n      type  # DataAsset, Transformation\n      metadata {\n        row_count\n        last_updated\n        quality_score\n      }\n    }\n    edges {\n      source_id\n      target_id\n      transformation_type  # glue_crawler, dbt_model, redshift_view\n      transformation_logic  # SQL query or Glue config\n      confidence  # 0-1 float\n    }\n  }\n}\n```\n\n**Implementation files:**\n- New component: `/Users/bado/iccha/brighthive/brighthive-webapp/src/components/LineageVisualization/index.tsx`\n- Use Cytoscape.js: `npm install cytoscape cytoscape-dagre`\n- Integration point: Asset detail page, dedicated lineage page\n\n**Performance optimization:**\n- Lazy loading: Load only 2 levels deep initially, expand on demand\n- Node limit: Warn user if graph >500 nodes, offer export to JSON\n- Caching: Cache lineage queries in Redux, invalidate on schema changes"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Lineage visualization enables impact analysis (what breaks if I change this?), debugging (why is this column null?), and compliance (prove data origin for audits). Critical for understanding data dependencies."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:21.412-0600",
    "updated": "2026-01-15T09:58:51.344-0600",
    "priority": "High",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-162",
    "summary": "Design Context-Rich Data Catalog UI",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design context-rich data catalog UI showing asset context (business purpose, quality, freshness, schema, lineage, governance)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Create UI mockup for context-rich catalog. Design component architecture (AssetContextCard, QualityBadge, FreshnessBadge, LineageVisualization). Document GraphQL query requirements. Design layout (grid vs list, filters, search)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of UI components (Sprint 2). Backend GraphQL resolver changes (covered in Task BH-150). Mobile responsive design."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Frontend"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 UI mockup created (Figma/Sketch): catalog page showing assets with context badges"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Component design: AssetContextCard (shows all context sections), QualityBadge (color-coded score), FreshnessBadge (SLA met/violated indicator)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 GraphQL query requirements: getDataAssets with fields (business_purpose, quality_score, last_updated, schema_version, lineage_summary, governance_tags)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Layout design: grid view (cards) with filters (quality score, freshness, org, compliance tags)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Interaction design: click asset \u2192 detail page, hover quality badge \u2192 show quality breakdown"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Accessibility: WCAG 2.1 AA compliance"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: UX Designer, Frontend Engineer, Product Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Existing catalog components to enhance:**\n- `/Users/bado/iccha/brighthive/brighthive-webapp/src/DataAssetCatalog/DataAssetCatalogPage/` - Main page\n- `/Users/bado/iccha/brighthive/brighthive-webapp/src/DataAssetCatalog/DataAssetCatalogGrid/` - Grid component\n- `/Users/bado/iccha/brighthive/brighthive-webapp/src/AssetDetail/AssetDetail.tsx` - Detail view\n\n**UI mockup (text representation):**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Data Catalog                                     [+ Add]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Filters: [Quality >0.8\u25bc] [Fresh <24h\u25bc] [Org: All\u25bc] [\ud83d\udd0d]   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 org_a.customers           \u2502  \u2502 org_b.sales           \u2502  \u2502\n\u2502  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500   \u2502  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502  \u2502\n\u2502  \u2502 Customer master data      \u2502  \u2502 Sales transactions    \u2502  \u2502\n\u2502  \u2502 Quality: [87\u25b2] Fresh: [\u2713]\u2502  \u2502 Quality: [72\u26a0] Fresh:[\u2717] \u2502\n\u2502  \u2502 Owner: jane@acme.com      \u2502  \u2502 Owner: bob@acme.com   \u2502  \u2502\n\u2502  \u2502 Updated: 3h ago           \u2502  \u2502 Updated: 2d ago       \u2502  \u2502\n\u2502  \u2502 [PII] [GDPR] [1M rows]    \u2502  \u2502 [Internal] [500K rows]\u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Component architecture:**\n```tsx\n<DataAssetCatalogGrid>\n  {assets.map(asset => (\n    <AssetContextCard\n      asset={asset}\n      context={{\n        businessPurpose: asset.business_purpose,\n        quality: <QualityBadge score={asset.quality_score} issues={asset.quality_issues} />,\n        freshness: <FreshnessBadge lastUpdated={asset.last_updated} sla={asset.update_sla} />,\n        schema: <SchemaBadge version={asset.schema_version} />,\n        governance: <GovernanceTags tags={asset.compliance_tags} />,\n        lineage: <LineagePreview upstreamCount={asset.lineage_summary.upstream} downstreamCount={asset.lineage_summary.downstream} />\n      }}\n    />\n  ))}\n</DataAssetCatalogGrid>\n```\n\n**GraphQL query:**\n```graphql\nquery getDataAssets($workspace_id: ID!) {\n  dataAssets(workspace_id: $workspace_id) {\n    uuid\n    name\n    business_purpose\n    business_owner\n    quality_score\n    completeness\n    quality_issues\n    last_updated\n    update_frequency\n    update_sla\n    sla_met\n    schema_version\n    column_count\n    data_classification\n    compliance_tags\n    lineage_summary {\n      upstream_count\n      downstream_count\n    }\n  }\n}\n```\n\n**QualityBadge design:**\n- Green (>0.9): \u2705 87\n- Yellow (0.7-0.9): \u26a0\ufe0f 72\n- Red (<0.7): \u274c 65\n- Hover: Show quality breakdown (completeness, accuracy, etc.)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Context-rich catalog enables analysts to quickly find high-quality, fresh datasets. Reduces time spent searching for reliable data, improves data discovery, and builds trust in data assets."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:20.241-0600",
    "updated": "2026-01-13T11:40:30.193-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-160",
    "summary": "Design Data Quality Monitoring",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Continuously monitor data quality metrics (completeness, accuracy, consistency, timeliness) using Glue DQ, DBT tests, and custom checks."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design data quality metric schema (6 dimensions). Document quality computation pipeline (Glue DQ, DBT tests, custom Lambda). Design storage (DynamoDB DataQualityMetrics + CloudWatch custom metrics). Create quality score algorithm (weighted average)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of quality checks (Sprint 2). Glue Data Quality rule creation. DBT test generation."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Data Pipeline, Infrastructure"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Data quality dimensions defined: completeness, uniqueness, accuracy, consistency, timeliness, validity"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Glue Data Quality integration: how to run DQ checks, parse results"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DBT tests integration: schema tests, data tests, parse test_results.json"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Custom Lambda checks: null rate, duplicate detection, pattern matching (email, phone)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DynamoDB DataQualityMetrics table: workspace_id (PK), asset_id#timestamp (SK), metrics JSON"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 CloudWatch custom metrics: BrightHive/DataQuality namespace"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Quality score formula: weighted average (0.2*completeness + 0.15*uniqueness + 0.25*accuracy + 0.15*consistency + 0.15*timeliness + 0.1*validity)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer, Quality Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Data quality dimensions:**\n```python\n{\n    \"asset_id\": \"asset-abc-123\",\n    \"timestamp\": 1705334400000,\n    \"completeness\": 0.92,       # % non-null\n    \"uniqueness\": 0.88,         # % unique (for columns that should be unique)\n    \"accuracy\": 0.95,           # % matching expected patterns (email format, phone)\n    \"consistency\": 0.90,        # % consistent with referential integrity\n    \"timeliness\": 0.85,         # % meeting SLA (last_updated within expected window)\n    \"validity\": 0.93,           # % passing validation rules\n    \"overall_score\": 0.91       # weighted average\n}\n```\n\n**Quality computation pipeline:**\n\n**1. Glue Data Quality:**\n- AWS Glue DQ: built-in data quality checks\n- Example rule: `Completeness \"email\" > 0.95`\n- Run DQ checks after Glue Crawler completes\n- Parse results from Glue API, push to Neo4j\n\n**2. DBT tests:**\n- Schema tests: `not_null`, `unique`, `accepted_values`, `relationships`\n- Data tests: custom SQL assertions\n- Parse DBT test_results.json: `/Users/bado/iccha/brighthive/brightbot/brightbot/agents/dbt_agent/`\n- Example: `SELECT COUNT(*) FROM customers WHERE email IS NULL` \u2192 completeness metric\n\n**3. Custom Lambda checks:**\n- Null rate: `SELECT COUNT(*), COUNT(column) FROM table`\n- Duplicates: `SELECT column, COUNT(*) FROM table GROUP BY column HAVING COUNT(*) > 1`\n- Pattern matching: regex for email, phone, SSN\n- Lambda triggered: EventBridge schedule (daily)\n\n**DynamoDB DataQualityMetrics table:**\n```python\n{\n    \"workspace_id\": \"ws-123\",               # Partition key\n    \"asset_id#timestamp\": \"asset-123#1705334400000\",  # Sort key\n    \"completeness\": 0.92,\n    \"uniqueness\": 0.88,\n    \"accuracy\": 0.95,\n    \"consistency\": 0.90,\n    \"timeliness\": 0.85,\n    \"validity\": 0.93,\n    \"overall_score\": 0.91\n}\n```\n\n**CloudWatch custom metrics:**\n- Namespace: `BrightHive/DataQuality`\n- Metrics: `QualityScore` (per asset), `Completeness`, `Accuracy`, etc.\n- Dimensions: `WorkspaceId`, `AssetId`, `OrganizationId`\n\n**Quality score algorithm:**\n```python\ndef compute_quality_score(metrics):\n    return (\n        0.20 * metrics['completeness'] +\n        0.15 * metrics['uniqueness'] +\n        0.25 * metrics['accuracy'] +\n        0.15 * metrics['consistency'] +\n        0.15 * metrics['timeliness'] +\n        0.10 * metrics['validity']\n    )\n```"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Continuous quality monitoring enables proactive issue detection, prevents bad data from entering pipelines, and builds trust in data assets. Analysts can filter by quality score to find reliable datasets."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2 (Jan 20-24, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:17.745-0600",
    "updated": "2026-01-16T09:13:06.280-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-159",
    "summary": "Design Context Change Audit Log",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Log every change to data lake context (schema, lineage, quality, governance) in DynamoDB AuditLogs table + CloudWatch Logs."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design DynamoDB AuditLogs table schema. Define event types (ASSET_ADDED, SCHEMA_CHANGED, LINEAGE_UPDATED, QUALITY_DEGRADED, etc.). Document event emission design (where in code to emit events). Create audit log query API (GraphQL resolver)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of logging middleware (Sprint 2). CloudWatch Insights queries. Audit log retention policy."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Infrastructure"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DynamoDB AuditLogs table design: workspace_id (PK), timestamp (SK), event_type, resource_id, changed_by, changes, trace_id"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Event types defined: ASSET_ADDED, ASSET_REMOVED, SCHEMA_CHANGED, LINEAGE_UPDATED, QUALITY_DEGRADED, FRESHNESS_SLA_VIOLATED, GOVERNANCE_POLICY_CHANGED"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Event emission design: middleware intercepts GraphQL mutations, emits events to DynamoDB + CloudWatch"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Audit log query API: GraphQL query getAuditLogs(workspace_id, start_date, end_date, event_type)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Trace ID generation: X-Ray trace ID or custom UUID for distributed tracing"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 CloudWatch Logs integration: emit structured logs for alerting"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Platform Engineer, Compliance Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**DynamoDB AuditLogs table:**\n```python\n{\n    \"workspace_id\": \"ws-123\",        # Partition key\n    \"timestamp\": 1705334400000,      # Sort key (milliseconds since epoch)\n    \"event_type\": \"SCHEMA_CHANGED\",  # or ASSET_ADDED, LINEAGE_UPDATED, etc.\n    \"resource_id\": \"asset-abc-123\",  # DataAsset UUID\n    \"resource_type\": \"DataAsset\",\n    \"changed_by\": \"glue_crawler\",    # or user_id or \"dbt_pipeline\"\n    \"changes\": {                     # JSON blob\n        \"schema_version\": {\"old\": \"v2.1\", \"new\": \"v2.2\"},\n        \"columns_added\": [\"phone_number\"],\n        \"columns_removed\": []\n    },\n    \"trace_id\": \"1-67891234-abcdef\",  # X-Ray trace ID\n    \"source_ip\": \"10.0.1.50\",\n    \"user_agent\": \"GraphQL-Client/1.0\"\n}\n```\n\n**Event types:**\n- ASSET_ADDED: New dataset discovered (Glue crawler, manual creation)\n- ASSET_REMOVED: Dataset deleted\n- SCHEMA_CHANGED: Columns added/removed/modified\n- LINEAGE_UPDATED: New lineage edge created\n- LINEAGE_BROKEN: Lineage edge removed (upstream dataset deleted)\n- QUALITY_DEGRADED: Quality score dropped below threshold\n- FRESHNESS_SLA_VIOLATED: Data not updated on time\n- GOVERNANCE_POLICY_CHANGED: Access rules modified\n\n**Event emission design:**\n- GraphQL middleware: intercept all mutations (createDataAsset, updateDataAsset, etc.)\n- Compare before/after state, emit event if changed\n- Lambda: emit event to DynamoDB + CloudWatch Logs (structured JSON)\n\n**Files to modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/resolvers/data-asset.ts` - Add audit logging\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/middleware/audit-logger.ts` - New middleware\n\n**Audit log query API:**\n```graphql\nquery getAuditLogs(\n  $workspace_id: ID!,\n  $start_date: DateTime!,\n  $end_date: DateTime!,\n  $event_type: String\n) {\n  auditLogs(workspace_id: $workspace_id, start_date: $start_date, end_date: $end_date, event_type: $event_type) {\n    timestamp\n    event_type\n    resource_id\n    changed_by\n    changes\n  }\n}\n```"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Audit logging enables compliance auditing (prove who changed what when), debugging (trace schema changes that broke pipelines), and security monitoring (detect unauthorized changes)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 1-2 (Jan 13-24, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:16.478-0600",
    "updated": "2026-01-13T11:40:27.885-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-154",
    "summary": "Design Lineage Capture from Existing Systems",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design automated lineage capture pipeline from Glue Crawler, DBT manifest.json, Redshift views, and OpenMetadata webhooks."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design lineage extraction from Glue GetTable API, DBT manifest.json, Redshift pg_views, OpenMetadata. Create Lambda function specs for lineage ingestion. Design lineage merge strategy when multiple sources provide conflicting lineage."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of Lambda functions (Sprint 2). SQL query parsing for Redshift views. DBT incremental model lineage."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline, Infrastructure"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Glue Crawler \u2192 Neo4j lineage extraction design (Lambda triggered by EventBridge)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DBT manifest.json \u2192 Neo4j lineage extraction design (parse depends_on, push to Neo4j)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Redshift pg_views \u2192 Neo4j lineage extraction design (parse SQL, extract source tables)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 OpenMetadata \u2192 Neo4j lineage sync design (webhook receiver updates Neo4j)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Lineage merge strategy documented (how to handle conflicting lineage from multiple sources)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Lambda function specs written (runtime, memory, IAM permissions)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer, Platform Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Existing integration points:**\n\n**1. Glue Crawler \u2192 Neo4j**\n- Existing: `/Users/bado/iccha/brighthive/brighthive-data-organization-cdk/glue_crawler_lambda/crawler_run/crawler_lambda.py`\n- Existing: `/Users/bado/iccha/brighthive/brighthive-data-organization-cdk/glue_crawler_lambda/crawler_run/ogm_client.py`\n- Enhancement: Extract lineage from Glue GetTable response, push to Neo4j\n\n**2. DBT \u2192 Neo4j**\n- DBT manifest.json location: S3 bucket (brighthive-dbt-artifacts/{workspace_id}/manifest.json)\n- Parse manifest: brightbot/brightbot/agents/dbt_agent/ (reference implementation)\n- Design: S3 event trigger \u2192 Lambda \u2192 Parse manifest \u2192 Push lineage to Neo4j\n\n**3. Redshift Views \u2192 Neo4j**\n- Existing: `/Users/bado/iccha/brighthive/brighthive-data-workspace-cdk/redshift_schema_query_lambda/main.py`\n- Query: `SELECT definition FROM pg_views WHERE schemaname = $1 AND viewname = $2`\n- Design: Parse SQL, extract source tables, create DERIVED_FROM edges\n\n**4. OpenMetadata \u2192 Neo4j**\n- Existing: `/Users/bado/iccha/brighthive/brighthive-platform-core/openmetadata_webhook_lambda/main.py`\n- Already tracks lineage, enhance to push to Neo4j\n\n**Lineage merge strategy:**\n- Prefer explicit lineage (DBT manifest, Glue) over inferred (SQL parsing)\n- Use confidence scores: Glue=1.0, DBT=1.0, SQL parsing=0.8\n- Merge: Take union of lineage edges, highest confidence wins for duplicates\n\n**Lambda IAM permissions:**\n- Glue: GetTable, GetDatabase\n- S3: GetObject (for DBT manifest)\n- Redshift Data API: ExecuteStatement\n- Neo4j: Network access (Security Group)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Automated lineage capture ensures lineage is always up-to-date without manual effort. Data engineers don't need to document lineage manually, reducing errors and improving trust in metadata."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2 (Jan 20-24, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:10.246-0600",
    "updated": "2026-01-15T09:58:43.466-0600",
    "priority": "High",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-153",
    "summary": "Design Multi-Level Lineage Graph",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Track lineage at multiple levels: dataset-level (DataAsset edges), transformation-level (Glue/DBT/Lambda jobs), and column-level (derived column relationships)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design multi-level lineage graph schema. Create Transformation node type (Glue job, DBT model, Redshift view, Lambda ETL). Define lineage relationships (DERIVED_FROM, INPUT_TO, OUTPUTS). Design column-level lineage (Column nodes with derivation logic)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Lineage extraction pipeline (Task BH-154). Lineage visualization UI (Task BH-163). Automated lineage propagation from source changes."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Lineage graph schema documented: DataAsset, Transformation, Column nodes with relationships"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Transformation node design: transformation_id, type (glue_job, dbt_model, redshift_view, lambda_etl), name, sql_query, config, created_by"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DERIVED_FROM relationship design: transformation_type, transformation_id, confidence, created_at"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Column-level lineage design: Column node with DERIVED_FROM edges, transformation_logic property"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Lineage query patterns designed: upstream, downstream, impact analysis (what breaks if dataset X changes)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Confidence scoring design: 1.0 for extracted lineage, <1.0 for inferred lineage"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer, Solutions Architect"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Files to create/modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/ogm/typedefs.ts` - Add Transformation, Column types\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/transformation.ts` - Already exists, extend\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/column.ts` - New model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/repository/neo4j/data-asset.ts` - Add lineage query methods\n\n**Lineage query patterns (Cypher):**\n```cypher\n// Upstream lineage (where did this dataset come from?)\nMATCH path = (target:DataAsset {uuid: $asset_id})<-[:DERIVED_FROM*]-(source:DataAsset)\nRETURN path\n\n// Downstream lineage (what uses this dataset?)\nMATCH path = (source:DataAsset {uuid: $asset_id})-[:DERIVED_FROM*]->(target:DataAsset)\nRETURN path\n\n// Impact analysis (what breaks if I delete this?)\nMATCH (asset:DataAsset {uuid: $asset_id})-[:DERIVED_FROM*]->(downstream:DataAsset)\nRETURN downstream\n\n// Transformation lineage (how is data transformed?)\nMATCH (source:DataAsset)-[:INPUT_TO]->(t:Transformation)-[:OUTPUTS]->(target:DataAsset)\nWHERE source.uuid = $asset_id\nRETURN t\n```\n\n**Column-level lineage example:**\n```cypher\n(Column {name: \"full_name\", type: \"VARCHAR\"})-[:DERIVED_FROM {\n  transformation_logic: \"CONCAT(first_name, ' ', last_name)\"\n}]->(Column {name: \"first_name\"})\n```\n\n**Sources for lineage:**\n- Glue Crawler: S3 file \u2192 Glue table\n- DBT manifest.json: model dependencies\n- Redshift pg_views: view definitions\n- Lambda CloudWatch Logs: ETL job logs (parse for S3 read/write)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Multi-level lineage enables impact analysis (what breaks if I change this dataset?), debugging (why is this column null?), and compliance (prove data origin for audits). Column-level lineage is critical for understanding derived metrics."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2 (Jan 20-24, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:09.095-0600",
    "updated": "2026-01-13T11:40:23.300-0600",
    "priority": "High",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-152",
    "summary": "Design Owner/Steward Model",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Track who owns, maintains, and governs each dataset through BusinessOwner, TechnicalSteward, and DataGovernancePolicy nodes with relationships to DataAsset."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design BusinessOwner, TechnicalSteward, DataGovernancePolicy node types. Define ownership relationships (OWNED_BY, MAINTAINED_BY, GOVERNED_BY). Design access control integration with GraphQL resolvers. Document governance policy structure (access rules, retention, compliance)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of access control enforcement (Sprint 2). UI for owner/steward management (Epic BH-114). Integration with Cognito user database."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Infrastructure"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 BusinessOwner node design: user_id, name, email, department, role"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 TechnicalSteward node design: user_id, name, email, team, responsibilities"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DataGovernancePolicy node design: policy_id, access_rules, retention_days, encryption_required, compliance_frameworks"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Relationships documented: OWNED_BY, MAINTAINED_BY, GOVERNED_BY, APPROVES_ACCESS_FOR"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Access control integration design (how affects GraphQL @authorized directive)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Migration plan for existing datasets without owners"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Security Lead, Solutions Architect, Compliance Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Files to create/modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/ogm/typedefs.ts` - Add new node types\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/business-owner.ts` - New model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/technical-steward.ts` - New model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/governance-policy.ts` - New model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/directives/authorized.ts` - Update authorization logic\n\n**Access control integration:**\n- GraphQL @authorized directive checks: user.role in policy.access_rules\n- Query: \"Can user X access dataset Y?\" \u2192 Follow GOVERNED_BY \u2192 Check policy.access_rules\n- Mutation: \"Update dataset metadata\" \u2192 Check if user is OWNED_BY or MAINTAINED_BY\n\n**Governance policy structure:**\n```json\n{\n  \"policy_id\": \"policy-123\",\n  \"access_rules\": [\n    {\"role\": \"analyst\", \"permissions\": [\"read\"]},\n    {\"role\": \"admin\", \"permissions\": [\"read\", \"write\", \"delete\"]},\n    {\"user_id\": \"user-456\", \"permissions\": [\"read\", \"write\"]}\n  ],\n  \"retention_days\": 365,\n  \"encryption_required\": true,\n  \"compliance_frameworks\": [\"GDPR\", \"HIPAA\"]\n}\n```\n\n**Integration with Cognito:**\n- Sync user metadata from Cognito User Pool\n- Map Cognito groups \u2192 governance roles"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Clear ownership enables data requests, schema change approvals, and compliance auditing. Governance policies enforce access control, data retention, and regulatory compliance (GDPR, HIPAA)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 1 (Jan 13-17, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:07.855-0600",
    "updated": "2026-01-13T11:40:22.457-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-151",
    "summary": "Design Schema Metadata Structure",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Track schema as first-class entity (SchemaVersion nodes) with evolution history, compatibility scoring, and drift detection capabilities."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design SchemaVersion node type in Neo4j. Define schema evolution relationships (EVOLVED_FROM, COMPATIBLE_WITH). Create schema comparison algorithm for detecting diffs. Design compatibility scoring for cross-org schema matching."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Schema extraction from Glue/Redshift (Task BH-154). UI for schema visualization (Epic BH-114). Automated schema drift detection pipeline."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 SchemaVersion node design documented with fields: schema_id, version, hash, created_at, columns, breaking_changes, created_by"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Relationship design: HAS_SCHEMA, EVOLVED_FROM, COMPATIBLE_WITH"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Schema diff algorithm designed (detect column additions, removals, type changes)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Compatibility scoring formula defined (Jaccard similarity for column names, type compatibility)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Design validated with real Glue Data Catalog schemas"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer, Platform Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Files to create/modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/ogm/typedefs.ts` - Add SchemaVersion type\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/schema-version.ts` - New model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/repository/neo4j/schema-version.ts` - New repository\n\n**Integration points:**\n- Glue Data Catalog GetTable API provides schema (columns, types)\n- Redshift pg_tables + information_schema.columns for Redshift schemas\n- DBT manifest.json contains model schemas\n\n**Algorithm design:**\n```python\ndef schema_diff(schema_old, schema_new):\n    added_columns = set(schema_new.columns) - set(schema_old.columns)\n    removed_columns = set(schema_old.columns) - set(schema_new.columns)\n    type_changes = [(col, old_type, new_type) for col in common_columns if types differ]\n    breaking_changes = removed_columns or type_changes\n    return {added, removed, type_changes, breaking_changes}\n```\n\n**Why first-class entity:**\n- Track schema evolution over time (when did email become nullable?)\n- Detect schema drift (Glue changed, Neo4j not updated)\n- Find compatible schemas across orgs"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Schema evolution tracking prevents breaking changes from propagating silently. Data engineers can see schema history, analysts can understand schema changes affecting their queries, and agents can warn about schema incompatibilities."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 1 (Jan 13-17, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:06.534-0600",
    "updated": "2026-01-13T11:40:21.720-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-150",
    "summary": "Design Asset Context Schema",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Extend DataAsset node in Neo4j with rich context fields for business metadata, quality metrics, freshness tracking, schema versioning, and governance policies."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design Neo4j schema extensions for DataAsset node. Document new properties: business_purpose, business_owner, technical_steward, quality_score, completeness, last_updated, update_frequency, update_sla, schema_version, schema_hash, data_classification, compliance_tags, access_tier. Create OGM type definitions in platform-core."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of schema extensions (Sprint 2). UI components for displaying new context. Agent integration for consuming context."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Infrastructure, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Neo4j schema extension document created with all new DataAsset properties"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 OGM TypeScript type definitions written for platform-core GraphQL API"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Migration script designed to add new properties to existing DataAsset nodes without downtime"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Design reviewed and approved by Solutions Architect and Data Engineer"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Storage strategy documented (Neo4j vs DynamoDB vs S3 for each context type)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Solutions Architect, Data Engineer, Platform Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Files to modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/ogm/typedefs.ts` - Add new fields to DataAsset type\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/data-asset.ts` - Update DataAsset model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/repository/neo4j/data-asset.ts` - Update repository methods\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/neo4j_connector_lambda/db/neo4j_connector.py` - Update connector for new fields\n\n**Design considerations:**\n- Use Neo4j native properties for frequently queried fields (quality_score, last_updated)\n- Consider DynamoDB for time-series quality metrics\n- Use Neo4j relationships for governance policies (separate nodes)\n\n**Storage strategy:**\n- Context metadata \u2192 Neo4j (fast graph queries)\n- Quality metrics history \u2192 DynamoDB DataQualityMetrics\n- Schema metadata \u2192 Neo4j as properties/nodes"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Rich asset context enables agents to make informed recommendations, analysts to find high-quality datasets quickly, and governance teams to enforce policies effectively. This is foundational for AI-first features in M2-M4."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "High | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 1 (Jan 13-17, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:04.675-0600",
    "updated": "2026-01-13T11:40:20.939-0600",
    "priority": "High",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-202",
    "summary": "do Claude Skills POC",
    "status": "To Do",
    "type": "Task",
    "description": null,
    "created": "2026-01-19T10:03:20.093-0600",
    "updated": "2026-01-19T10:04:40.923-0600",
    "priority": "Medium",
    "assignee": "Matt Gee",
    "labels": [
      "agent-framework"
    ]
  },
  {
    "key": "BH-201",
    "summary": "Onboarding & Offboarding 100% working ",
    "status": "Needs Refinement",
    "type": "Task",
    "description": null,
    "created": "2026-01-16T09:18:41.339-0600",
    "updated": "2026-01-16T09:18:48.690-0600",
    "priority": "Medium",
    "assignee": "Ahmed Elsherbiny",
    "labels": []
  },
  {
    "key": "BH-161",
    "summary": "Design Monitoring Decision (data lake focus)",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Monitor data lake health (not just system health) using CloudWatch custom metrics for assets, schemas, quality, freshness, and lineage."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design CloudWatch custom metrics for data lake health. Define alarm rules for quality degradation, SLA violations, lineage breaks. Create monitoring dashboard design (CloudWatch Dashboard or Grafana). Document metric collection strategy (Lambda emits metrics)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of metric emission (Sprint 2). Grafana deployment. PagerDuty integration."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Infrastructure, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 CloudWatch custom metrics designed: BrightHive/DataLake namespace with AssetsIngested, SchemaChanges, QualityScoreDrop, FreshnessSLAViolations, LineageEdgesAdded, LineageEdgesBroken"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Alarm definitions: Critical alarms (QualityScoreDrop >5 in 5min, FreshnessSLAViolations >0), Warning alarms (SchemaChanges >10 in 1hr, LineageEdgesBroken >0)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Monitoring dashboard design: CloudWatch Dashboard with widgets for each metric, grouped by workspace/org"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Metric collection strategy: Lambda emits metrics after quality checks, schema changes, lineage updates"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Confirmed: CloudWatch + X-Ray for M1 (not Prometheus)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Platform Engineer, Data Engineer, SRE Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**CloudWatch custom metrics:**\n```python\nimport boto3\ncloudwatch = boto3.client('cloudwatch')\n\n# Example: Emit QualityScoreDrop metric\ncloudwatch.put_metric_data(\n    Namespace='BrightHive/DataLake',\n    MetricData=[\n        {\n            'MetricName': 'QualityScoreDrop',\n            'Dimensions': [\n                {'Name': 'WorkspaceId', 'Value': 'ws-123'},\n                {'Name': 'AssetId', 'Value': 'asset-abc'},\n            ],\n            'Value': 0.15,  # Dropped by 15%\n            'Unit': 'None'\n        }\n    ]\n)\n```\n\n**Metrics to track:**\n- **AssetsIngested**: Count of new datasets discovered (per workspace/org)\n- **SchemaChanges**: Count of schema modifications (per workspace/org)\n- **QualityScoreDrop**: Count of assets with quality score drop >10% (threshold alert)\n- **FreshnessSLAViolations**: Count of datasets not updated within SLA (critical alert)\n- **LineageEdgesAdded**: Count of new lineage relationships\n- **LineageEdgesBroken**: Count of lineage edges removed (upstream deleted) - alert immediately\n\n**Alarm definitions:**\n```python\n# Critical alarm\ncloudwatch.put_metric_alarm(\n    AlarmName='DataLake-QualityScoreDrop-Critical',\n    MetricName='QualityScoreDrop',\n    Namespace='BrightHive/DataLake',\n    Statistic='Sum',\n    Period=300,  # 5 minutes\n    EvaluationPeriods=1,\n    Threshold=5,  # More than 5 assets with quality drop\n    ComparisonOperator='GreaterThanThreshold',\n    TreatMissingData='notBreaching'\n)\n\n# Warning alarm\ncloudwatch.put_metric_alarm(\n    AlarmName='DataLake-SchemaChanges-Warning',\n    MetricName='SchemaChanges',\n    Namespace='BrightHive/DataLake',\n    Statistic='Sum',\n    Period=3600,  # 1 hour\n    EvaluationPeriods=1,\n    Threshold=10,  # More than 10 schema changes in 1 hour\n    ComparisonOperator='GreaterThanThreshold'\n)\n```\n\n**Dashboard design:**\n- Widget 1: Asset health (assets by quality score tier: >0.9, 0.7-0.9, <0.7)\n- Widget 2: Schema changes timeline (line graph, last 7 days)\n- Widget 3: Freshness SLA compliance (% meeting SLA)\n- Widget 4: Lineage health (edges added vs broken)\n- Widget 5: Alarm status (critical/warning/ok)\n\n**X-Ray integration:**\n- Trace context propagation through Lambda \u2192 Neo4j \u2192 GraphQL\n- Identify slow queries, bottlenecks"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\n\n**Files to modify:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/brighthive_core/core_subgraph_api_stack.py` - Add CloudWatch alarm creation\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/middleware/metrics-emitter.ts` - Create metrics emission middleware\n\n**Files to create:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/quality_monitoring/main.py` - Emit quality metrics\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/lineage_monitoring/main.py` - Emit lineage metrics"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Data lake monitoring enables proactive issue detection before users report problems. SRE teams get alerted to quality degradation, schema drift, and lineage breaks. Reduces data incident resolution time."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Medium | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026) - Finalize in Sprint 2"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:19.017-0600",
    "updated": "2026-01-15T09:58:49.532-0600",
    "priority": "Medium",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-157",
    "summary": "Design Context Snapshot Strategy",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design context snapshot strategy for capturing entire context graph at point in time (reproducibility, debugging, rollback)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design ContextSnapshot node with snapshot metadata. Define storage strategy (Neo4j for small, S3 for large snapshots). Create DynamoDB ContextVersions table for fast lookup. Document snapshot export/import pipeline."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of snapshot pipeline (Sprint 2). Snapshot scheduling (cron/EventBridge). Snapshot retention policy."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Infrastructure"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 ContextSnapshot node design: snapshot_id, version, created_at, snapshot_metadata (workspace_id, created_by, reason)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 INCLUDES relationships: (ContextSnapshot)-[:INCLUDES]->(DataAsset/SchemaVersion/Transformation)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Storage strategy: Neo4j for small changes (<10MB), S3 for large snapshots (>10MB, compressed JSON)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DynamoDB ContextVersions table design: workspace_id (PK), version (SK), snapshot_timestamp, s3_uri"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Snapshot export pipeline: Neo4j export \u2192 JSON \u2192 gzip \u2192 S3"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Snapshot import pipeline: S3 download \u2192 decompress \u2192 Neo4j import"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Platform Engineer, Data Engineer"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Storage strategy:**\n\n**Neo4j (for small changes):**\n- ContextSnapshot node with INCLUDES relationships\n- Efficient for <1000 nodes, <10MB\n- Query: `MATCH (snap:ContextSnapshot {snapshot_id: $id})-[:INCLUDES]->(n) RETURN n`\n\n**S3 (for large snapshots):**\n- Export entire workspace subgraph to JSON\n- Compress with gzip\n- Store: `s3://brighthive-context-snapshots-prod/{workspace_id}/{version}.json.gz`\n- Lifecycle policy: Glacier after 90 days\n\n**DynamoDB ContextVersions table:**\n```python\n{\n    \"workspace_id\": \"ws-123\",         # Partition key\n    \"version\": \"v2026-01-15\",         # Sort key\n    \"snapshot_timestamp\": 1705334400,\n    \"s3_uri\": \"s3://...\",\n    \"created_by\": \"admin@brighthive.io\",\n    \"reason\": \"monthly_snapshot\",\n    \"size_bytes\": 52428800\n}\n```\n\n**Snapshot export pipeline (Cypher \u2192 JSON):**\n```cypher\n// Export workspace subgraph\nMATCH (ws:Workspace {workspace_id: $workspace_id})\nMATCH (ws)<-[:IN_WORKSPACE]-(asset:DataAsset)\nMATCH (asset)-[:HAS_SCHEMA]->(schema:SchemaVersion)\nMATCH (asset)-[lineage:DERIVED_FROM]->(source:DataAsset)\nRETURN ws, asset, schema, lineage, source\n```\n\n**Use cases:**\n- Reproducibility: \"Show me the data catalog as of Jan 1, 2026\"\n- Debugging: \"What changed between v1 and v2?\"\n- Rollback: \"Revert to previous context state (undo bad metadata update)\"\n\n**Lambda design:**\n- Triggered: Manual (API call) or Scheduled (EventBridge)\n- Runtime: Python 3.12, 15-min timeout, 10GB ephemeral storage\n- IAM: Neo4j network access, S3 PutObject, DynamoDB PutItem"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\n\n**Files to create:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/models/context-snapshot.ts` - ContextSnapshot model\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/repository/neo4j/context-snapshot.ts` - Snapshot repository\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/context_snapshot/export.py` - Snapshot export Lambda\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/context_snapshot/import.py` - Snapshot import Lambda\n\n**DynamoDB table to create:**\n- ContextVersions (workspace_id PK, version SK) via CDK"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Context snapshots enable auditing (prove compliance at point in time), debugging (compare before/after), and disaster recovery (restore metadata after accidental deletion)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Medium | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:14.053-0600",
    "updated": "2026-01-13T11:40:26.440-0600",
    "priority": "Medium",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-156",
    "summary": "Design Master Data / Golden Record Strategy",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Identify golden records across organizations using heuristics (largest, most complete, most recent) and manual admin designation."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design master data properties (is_master_data, master_data_for, master_data_confidence, master_data_source). Create master data identification algorithm. Design MASTER_FOR, DERIVED_COPY relationships. Document admin UI spec for manual designation."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of master data algorithm (Sprint 2). UI for master data management (Epic BH-114). Master data sync across orgs."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Master data properties designed: is_master_data (boolean), master_data_for (array of entity types), master_data_confidence (0-1 float), master_data_source (string)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Master data identification algorithm: score based on row count, completeness, last_updated"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 MASTER_FOR relationship: (DataAsset)-[:MASTER_FOR {entity: 'customer'}]->(Workspace)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DERIVED_COPY relationship: (slave:DataAsset)-[:DERIVED_COPY]->(master:DataAsset)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Admin UI spec: table listing candidate master datasets, manual designation button"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Migration plan for existing datasets (auto-detect master data)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Solutions Architect, Data Engineer"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Master data identification algorithm:**\n```python\ndef identify_master_data(datasets: list[DataAsset]) -> DataAsset:\n    # Heuristics:\n    # 1. Largest (most rows)\n    # 2. Most complete (highest completeness %)\n    # 3. Most recent (last_updated timestamp)\n    # 4. Highest quality (quality_score)\n\n    scored_datasets = []\n    for ds in datasets:\n        score = (\n            0.3 * normalize(ds.row_count) +\n            0.3 * ds.completeness +\n            0.2 * recency_score(ds.last_updated) +\n            0.2 * ds.quality_score\n        )\n        scored_datasets.append((ds, score))\n\n    # Return highest score\n    master = max(scored_datasets, key=lambda x: x[1])\n    return master[0], master[1]  # dataset, confidence\n```\n\n**Problem example:**\n- Workspace has 10 orgs, each has \"customers\" table\n- Same customer (email: john@acme.com) appears in Org A, B, C\n- Which is source of truth?\n\n**Solution:**\n- Run master data algorithm across all org \"customers\" tables\n- Org A has 1M rows, Org B has 100K rows \u2192 Org A likely master\n- Manual override: admin can designate Org B as master if business logic requires\n\n**Relationships:**\n```cypher\n// Org A customers is master\n(orgA:DataAsset {name: \"customers\", is_master_data: true, master_data_for: [\"customer\"]})-[:MASTER_FOR {entity: \"customer\"}]->(ws:Workspace)\n\n// Org B customers is derived copy\n(orgB:DataAsset {name: \"customers\"})-[:DERIVED_COPY]->(orgA:DataAsset)\n```\n\n**Admin UI spec:**\n- Table: List all datasets with same name across orgs\n- Columns: Org, row_count, completeness, last_updated, quality_score, master_confidence\n- Action: \"Designate as Master\" button"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\n\n**Files to create:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/service/neo4j/master-data.ts` - Master data service\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/master_data_detection/main.py` - Master data detection Lambda\n- `/Users/bado/iccha/brighthive/brighthive-webapp/src/AdminPanel/MasterDataManagement/` - Admin UI component"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Master data designation prevents duplicate data, enables single source of truth for entities (customers, products), and supports data consolidation efforts. Critical for multi-org workspaces."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Medium | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:12.729-0600",
    "updated": "2026-01-13T11:40:25.665-0600",
    "priority": "Medium",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-155",
    "summary": "Design Cross-Organization Schema Matching",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Find related datasets across organizations using schema similarity scoring (Jaccard, type compatibility, semantic embeddings)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design schema similarity algorithm. Create batch job spec for computing similarity scores (nightly run). Design SIMILAR_TO relationship with score property. Document semantic similarity using embeddings (OpenAI text-embedding-3-small)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of similarity computation (Sprint 2). Embedding generation pipeline. UI for browsing similar schemas (Epic BH-114)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, Data Pipeline, BrightAgent"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Schema similarity algorithm designed with 3 components: Jaccard similarity (column name overlap), type compatibility (matching data types), semantic similarity (embedding cosine distance)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Weighted scoring formula: 0.4*jaccard + 0.3*type_score + 0.3*semantic_score"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Batch job design: nightly Lambda, compares all schemas in workspace, stores top 10 similar schemas per dataset"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 SIMILAR_TO relationship design: score property (0-1 float)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Embedding strategy: concatenate schema description + column names, embed with OpenAI API"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Performance analysis: O(n\u00b2) comparisons, optimization strategies documented"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer, AI/ML Lead"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Algorithm design:**\n```python\nfrom openai import OpenAI\n\ndef schema_similarity(schema_a, schema_b):\n    # 1. Column name overlap (Jaccard similarity)\n    cols_a = set([col['name'] for col in schema_a.columns])\n    cols_b = set([col['name'] for col in schema_b.columns])\n    jaccard = len(cols_a & cols_b) / len(cols_a | cols_b)\n\n    # 2. Data type compatibility\n    common_cols = cols_a & cols_b\n    type_match = sum(1 for col in common_cols\n                     if schema_a[col].type == schema_b[col].type)\n    type_score = type_match / len(common_cols) if common_cols else 0\n\n    # 3. Semantic similarity (using embeddings)\n    client = OpenAI()\n    desc_a = f\"{schema_a.description} {' '.join(cols_a)}\"\n    desc_b = f\"{schema_b.description} {' '.join(cols_b)}\"\n    emb_a = client.embeddings.create(input=desc_a, model=\"text-embedding-3-small\").data[0].embedding\n    emb_b = client.embeddings.create(input=desc_b, model=\"text-embedding-3-small\").data[0].embedding\n    semantic_score = cosine_similarity(emb_a, emb_b)\n\n    # Weighted score\n    return 0.4 * jaccard + 0.3 * type_score + 0.3 * semantic_score\n```\n\n**Batch job design:**\n- Lambda: 15-min timeout, 3GB memory\n- Fetch all SchemaVersion nodes from Neo4j (workspace scope)\n- Compute pairwise similarity (O(n\u00b2))\n- Optimization: Only compare schemas with >3 common columns (pre-filter)\n- Store: SIMILAR_TO relationships for score >0.5\n\n**Integration with BrightBot:**\n- Retrieval Agent can query: \"Find datasets similar to org_a.customers\"\n- Cypher: `MATCH (a:DataAsset)-[:HAS_SCHEMA]->()-[:SIMILAR_TO {score: >0.7}]->()<-[:HAS_SCHEMA]-(b:DataAsset)`"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\n\n**Files to create:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/service/neo4j/schema-similarity.ts` - Similarity computation service\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/lambdas/schema_similarity_batch/main.py` - Nightly batch job\n- `/Users/bado/iccha/brighthive/brightbot/brightbot/tools/schema_similarity.py` - Tool for BrightBot to query similar schemas"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Cross-org schema matching enables data consolidation, analysts can discover datasets from other orgs with similar structure, and agents can suggest relevant datasets for joins/unions."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Medium | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 2-3 (Jan 20-31, 2026)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:11.559-0600",
    "updated": "2026-01-15T09:58:46.105-0600",
    "priority": "Medium",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-149",
    "summary": "Implement distributed task queue with worker scaling",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Build task queue system that auto-scales workers based on load for processing big data tasks"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:05:02.790-0600",
    "updated": "2026-01-13T11:36:06.313-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-148",
    "summary": "Design parallel processing architecture for large datasets",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create architecture for distributing complex queries across multiple workers"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:05:01.150-0600",
    "updated": "2026-01-13T11:36:05.552-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-145",
    "summary": "Implement Microsoft Teams integration",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create Teams app for sending notifications and enabling bot interactions within Teams channels"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:56.693-0600",
    "updated": "2026-01-13T11:36:03.557-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-144",
    "summary": "Implement Slack integration for notifications and commands",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Build Slack app with webhooks for notifications and slash commands for interactions"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:55.215-0600",
    "updated": "2026-01-13T11:36:02.794-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-143",
    "summary": "Implement automation workflow engine",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Build rule-based automation engine for triggering actions based on project events"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:53.769-0600",
    "updated": "2026-01-13T11:36:01.996-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-142",
    "summary": "Design project container and workspace model",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Define data model for projects as containers of contexts, automations, and configurations"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:52.438-0600",
    "updated": "2026-01-13T11:36:01.300-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-141",
    "summary": "Implement enhancement data ingestion pipeline",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Add OMD for the PII"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:51.127-0600",
    "updated": "2026-01-18T21:24:44.600-0600",
    "priority": "Medium",
    "assignee": "Ahmed Elsherbiny",
    "labels": []
  },
  {
    "key": "BH-140",
    "summary": "Design connector architecture for sources and destinations",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create plugin architecture for connecting various data sources and destinations (APIs, databases, files)"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:49.774-0600",
    "updated": "2026-01-13T11:35:59.915-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-139",
    "summary": "Implement responsive navigation and component library updates",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Refactor navigation components and update design system for consistency"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:48.236-0600",
    "updated": "2026-01-13T11:35:59.236-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-138",
    "summary": "Design new UI/UX mockups for latest features",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create Figma designs for updated navigation, layouts, and new feature integrations"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:46.593-0600",
    "updated": "2026-01-13T11:35:58.597-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-137",
    "summary": "Implement distributed tracing and logging",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Add tracing instrumentation to track request flows and debug issues across services"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:45.033-0600",
    "updated": "2026-01-16T09:16:28.217-0600",
    "priority": "Medium",
    "assignee": "Ahmed Elsherbiny",
    "labels": []
  },
  {
    "key": "BH-136",
    "summary": "Set up performance monitoring and observability stack",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Deploy monitoring tools (Prometheus, Grafana) for tracking system performance and health"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:43.654-0600",
    "updated": "2026-01-16T09:16:25.048-0600",
    "priority": "Medium",
    "assignee": "Ahmed Elsherbiny",
    "labels": []
  },
  {
    "key": "BH-135",
    "summary": "Build persona analytics dashboard",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create UI for visualizing persona insights, usage patterns, and effectiveness metrics"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:42.161-0600",
    "updated": "2026-01-13T11:35:56.643-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-134",
    "summary": "Design persona data model and customization engine",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Define data structure for storing persona attributes, preferences, and behavioral patterns"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:40.710-0600",
    "updated": "2026-01-13T11:35:56.038-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-133",
    "summary": "Implement agent-to-agent communication protocol",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Build messaging system for agents to share information and coordinate on complex tasks"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:39.333-0600",
    "updated": "2026-01-13T11:35:55.394-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-132",
    "summary": "Design multi-agent orchestration framework",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Create architecture for coordinating multiple AI agents, including task delegation and communication protocols"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:38.003-0600",
    "updated": "2026-01-13T11:35:54.712-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-131",
    "summary": "Implement context retrieval API endpoints",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Build REST API endpoints for creating, reading, updating, and retrieving context data with proper authentication"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:36.619-0600",
    "updated": "2026-01-13T11:35:53.919-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-130",
    "summary": "Design context storage schema and data model",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Define the database schema for storing context data, including versioning, metadata, and relationships between contexts"
            }
          ]
        }
      ]
    },
    "created": "2026-01-11T21:04:35.155-0600",
    "updated": "2026-01-13T11:35:53.275-0600",
    "priority": "Medium",
    "assignee": "Unassigned",
    "labels": []
  },
  {
    "key": "BH-169",
    "summary": "Design Context Injection for Agents (SIMPLE)",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design lightweight context injection for agents (add workspace_context field to BBState, fetch once per conversation, cache in Redis)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design BBState extension (add workspace_context field). Document context fetch function (query Neo4j/DynamoDB for workspace metadata). Design caching strategy (Redis, 5-min TTL). Keep implementation SIMPLE (no user behavior tracking, no multi-tier memory)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of context injection (Sprint 2). User behavioral tracking (defer to M2). Multi-tier memory system (over-engineering)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "BrightAgent"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 BBState extension: add workspace_context field (workspace_id, total_assets, master_datasets, quality_sla, compliance_frameworks)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Context fetch function: query Neo4j for workspace summary, DynamoDB for config"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Caching strategy: Redis cache with 5-min TTL, key: workspace_id"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Context injection: fetch once at conversation start, inject into agent prompts"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 NOT overbuilt: no user behavior tracking, no full Neo4j graph fetch, no multi-tier memory"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Performance: <100ms to fetch, <10KB payload"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: AI/ML Lead"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**BBState extension:**\n\n**Current BBState:**\n- File: `/Users/bado/iccha/brighthive/brightbot/brightbot/workflows/states.py`\n- Existing fields: messages, user_id, workspace_id, organization_id, etc.\n\n**NEW addition (minimal):**\n```python\nclass BBState(TypedDict):\n    # ...existing fields...\n\n    # Data lake context (fetched once per conversation)\n    workspace_context: dict | None  # {\n    #   \"workspace_id\": \"ws-123\",\n    #   \"total_assets\": 150,\n    #   \"master_datasets\": [\"org_a.customers\"],\n    #   \"quality_sla\": 0.80,\n    #   \"compliance_frameworks\": [\"GDPR\", \"HIPAA\"],\n    #   \"top_datasets\": [  # Top 5 by usage (simple heuristic)\n    #     {\"name\": \"org_a.customers\", \"quality\": 0.92},\n    #     {\"name\": \"org_b.sales\", \"quality\": 0.87}\n    #   ]\n    # }\n```\n\n**Context fetch function:**\n```python\nimport redis\nfrom neo4j import GraphDatabase\n\ndef fetch_workspace_context(workspace_id: str) -> dict:\n    # Check Redis cache first\n    redis_client = redis.Redis()\n    cache_key = f\"workspace_context:{workspace_id}\"\n    cached = redis_client.get(cache_key)\n    if cached:\n        return json.loads(cached)\n\n    # Fetch from Neo4j\n    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))\n    with driver.session() as session:\n        result = session.run('\"'\n            MATCH (ws:Workspace {workspace_id: $workspace_id})\n            MATCH (ws)<-[:IN_WORKSPACE]-(asset:DataAsset)\n            OPTIONAL MATCH (asset)-[:MASTER_FOR]->(ws)\n            RETURN\n                count(asset) as total_assets,\n                collect(CASE WHEN asset.is_master_data THEN asset.name END) as master_datasets,\n                collect({name: asset.name, quality: asset.quality_score})[0..5] as top_datasets\n        '\"', workspace_id=workspace_id)\n        data = result.single()\n\n    # Fetch config from DynamoDB\n    dynamodb = boto3.resource('dynamodb')\n    table = dynamodb.Table('WorkspaceConfig')\n    config = table.get_item(Key={'workspace_id': workspace_id}).get('Item', {}).get('config', {})\n\n    context = {\n        \"workspace_id\": workspace_id,\n        \"total_assets\": data[\"total_assets\"],\n        \"master_datasets\": [d for d in data[\"master_datasets\"] if d],\n        \"quality_sla\": config.get(\"quality_rules\", {}).get(\"min_quality_score\", 0.80),\n        \"compliance_frameworks\": config.get(\"governance_policies\", {}).get(\"compliance_frameworks\", []),\n        \"top_datasets\": data[\"top_datasets\"]\n    }\n\n    # Cache for 5 minutes\n    redis_client.setex(cache_key, 300, json.dumps(context))\n\n    return context\n```\n\n**Context injection (agent prompt):**\n```python\n# In agent system prompt\nsystem_prompt = f'\"'\nYou are BrightBot, an AI assistant for data analysis.\n\nWorkspace context:\n- Total datasets: {workspace_context['total_assets']}\n- Master datasets: {', '.join(workspace_context['master_datasets'])}\n- Quality SLA: {workspace_context['quality_sla']}\n- Compliance: {', '.join(workspace_context['compliance_frameworks'])}\n\nTop datasets:\n{[f\"- {ds['name']} (quality: {ds['quality']})\" for ds in workspace_context['top_datasets']]}\n\nWhen recommending datasets, prefer master datasets and high-quality datasets.\n'\"'\n```\n\n**NOT overbuilt (what we're NOT doing):**\n- \u274c Don't fetch entire Neo4j graph (too slow, >100ms)\n- \u274c Don't track user behavior (page views, dataset access, query history) - defer to M2\n- \u274c Don't build multi-tier memory system (short-term, long-term, persistent) - over-engineering\n- \u274c Don't inject full dataset schemas into prompts - query on demand via agent tools\n\n**Implementation files:**\n- BBState: `/Users/bado/iccha/brighthive/brightbot/brightbot/workflows/states.py`\n- Context fetch: `/Users/bado/iccha/brighthive/brightbot/brightbot/utils/context_fetcher.py` (new)\n- Integration: `/Users/bado/iccha/brighthive/brightbot/brightbot/agents/super_agent/middleware/initialization.py`\n\n**Performance:**\n- Neo4j query: <50ms (simple aggregation)\n- DynamoDB query: <10ms (point lookup)\n- Redis cache hit: <5ms\n- Total: <100ms (first fetch), <5ms (cached)\n- Payload size: <10KB"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Lightweight context injection enables agents to make workspace-aware recommendations without over-engineering. Agents understand workspace configuration, master datasets, and quality standards."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Low | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026) - Bonus if time allows"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:28.328-0600",
    "updated": "2026-01-15T14:03:36.765-0600",
    "priority": "Low",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-168",
    "summary": "Design Agent Context Query API",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design GraphQL queries for agents to consume data lake context (findDatasetsByPurpose, getDatasetQuality, getDatasetSchema)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design agent query API (GraphQL schema extensions). Document queries: findDatasetsByPurpose (Retrieval Agent), getDatasetQuality (Analyst Agent), getDatasetSchema (DBT Agent). Create example agent queries for documentation."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of GraphQL resolvers (Sprint 2). Agent integration (Task BH-169). RAG integration for semantic search."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend, BrightAgent"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Agent query API spec (GraphQL schema extensions) with 3 queries: findDatasetsByPurpose, getDatasetQuality, getDatasetSchema"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 findDatasetsByPurpose: full-text search on business_purpose, returns assets with quality/freshness context"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 getDatasetQuality: returns quality metrics, issues, last_checked for quality assessment"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 getDatasetSchema: returns SchemaVersion with columns, types for DBT code generation"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Example agent queries documented for each agent type (Retrieval, Analyst, DBT)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Performance consideration: add indexes to Neo4j for business_purpose full-text search"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Solutions Architect, AI/ML Lead"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Agent query API spec:**\n\n```graphql\n# Retrieval Agent: Find datasets by business purpose\nquery findDatasetsByPurpose(\n  $query: String!,\n  $workspace_id: ID!,\n  $min_quality_score: Float,  # Optional filter\n  $only_fresh: Boolean  # Optional: only assets meeting SLA\n) {\n  datasets(\n    workspace_id: $workspace_id,\n    search: $query,\n    min_quality_score: $min_quality_score,\n    only_fresh: $only_fresh\n  ) {\n    uuid\n    name\n    business_purpose\n    business_owner\n    quality_score\n    completeness\n    last_updated\n    update_frequency\n    sla_met\n    lineage_summary {\n      upstream_count\n      downstream_count\n    }\n    governance {\n      data_classification\n      compliance_tags\n    }\n  }\n}\n\n# Analyst Agent: Get dataset quality before querying\nquery getDatasetQuality($asset_id: ID!) {\n  dataAsset(id: $asset_id) {\n    uuid\n    name\n    quality_score\n    completeness\n    accuracy\n    quality_issues\n    last_updated\n    sla_met\n    quality_history {  # Last 7 days\n      timestamp\n      quality_score\n      completeness\n    }\n  }\n}\n\n# DBT Agent: Get schema for model generation\nquery getDatasetSchema($asset_id: ID!) {\n  dataAsset(id: $asset_id) {\n    uuid\n    name\n    schema {\n      version\n      hash\n      columns {\n        name\n        type\n        nullable\n        primary_key\n        description\n      }\n    }\n    sample_queries\n  }\n}\n\n# Governance Agent: Get governance context\nquery getDatasetGovernance($asset_id: ID!) {\n  dataAsset(id: $asset_id) {\n    uuid\n    name\n    data_classification\n    compliance_tags\n    business_owner\n    technical_steward\n    governance_policy {\n      access_rules {\n        role\n        permissions\n      }\n      retention_days\n      encryption_required\n    }\n  }\n}\n```\n\n**Example agent queries:**\n\n**1. Retrieval Agent:**\n```python\n# User asks: \"Find customer data with high quality\"\nquery = r'\"'\nquery {\n  datasets(\n    workspace_id: \"ws-123\",\n    search: \"customer\",\n    min_quality_score: 0.85,\n    only_fresh: true\n  ) {\n    name\n    business_purpose\n    quality_score\n    last_updated\n  }\n}\n'\"'\n# Agent processes results, recommends: \"I found org_a.customers (quality: 0.92, updated 3h ago)\"\n```\n\n**2. Analyst Agent:**\n```python\n# Before executing query, check quality\nquery = r'\"'\nquery {\n  dataAsset(id: \"asset-123\") {\n    name\n    quality_score\n    quality_issues\n    sla_met\n  }\n}\n'\"'\n# Agent warns: \"Warning: org_b.sales has quality score 0.68 (20% nulls in revenue column)\"\n```\n\n**3. DBT Agent:**\n```python\n# Generate DBT model from schema\nquery = r'\"'\nquery {\n  dataAsset(id: \"asset-456\") {\n    name\n    schema {\n      columns {\n        name\n        type\n        nullable\n      }\n    }\n  }\n}\n'\"'\n# Agent generates: SELECT customer_id, email, created_at FROM org_a.customers\n```\n\n**Implementation files:**\n- GraphQL schema: `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/schema/typedefs.ts`\n- Resolvers: `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/resolvers/data-asset.ts`\n- Neo4j full-text index: Create index on business_purpose for fast search\n\n**Performance optimization:**\n- Neo4j full-text index: `CREATE FULLTEXT INDEX business_purpose_idx FOR (n:DataAsset) ON EACH [n.business_purpose]`\n- Query: `CALL db.index.fulltext.queryNodes('business_purpose_idx', $query)`\n- Limit results: max 50 datasets per query"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Agent query API enables agents to access rich data lake context, improving recommendation quality, data discovery, and user experience. Agents can warn about low-quality data before analysis."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Low | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026) - Bonus if time allows"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:27.310-0600",
    "updated": "2026-01-15T14:03:35.973-0600",
    "priority": "Low",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-167",
    "summary": "Design Connector Developer Guide",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Write connector developer guide (Markdown) with architecture, metadata spec, authentication, examples, testing, troubleshooting sections."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Write connector developer guide outline. Document architecture overview, metadata specification (reference Task BH-166), authentication (Cognito JWT), example implementations (Glue, Airbyte, custom Python/TypeScript), testing guide, troubleshooting common errors."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of connector SDK (Sprint 2). Video tutorials. Interactive documentation."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Documentation"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Connector developer guide (Markdown) with 6 sections: Architecture, Metadata Spec, Authentication, Examples, Testing, Troubleshooting"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Architecture section: explain connector flow, integration points, Neo4j graph model"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Metadata spec section: reference Task BH-166 JSON schema, provide field descriptions"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Authentication section: how to get Cognito JWT, include in GraphQL request"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Example implementations: Glue connector (Python), custom connector (TypeScript), include full code snippets"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Testing guide: how to validate payload, test against staging environment"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Troubleshooting: common errors (authentication failed, invalid schema, missing fields) with solutions"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Technical Writer, Developer Relations"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Connector developer guide outline:**\n\n# BrightHive Connector Developer Guide\n\n## 1. Architecture Overview\n- Connector flow diagram: [Data Source] \u2192 [Connector] \u2192 [Platform Core GraphQL API] \u2192 [Neo4j]\n- Integration points: Cognito (auth), GraphQL API (metadata), Neo4j (storage)\n- Neo4j graph model: DataAsset, SchemaVersion, Transformation nodes\n- Supported data sources: Glue, Airbyte, Snowflake, custom\n\n## 2. Metadata Specification\n- Reference: Task BH-166 JSON schema\n- Required fields: asset.name, asset.type, asset.location\n- Optional fields: schema, lineage, quality, governance\n- Field descriptions:\n  - asset.type: \"table\", \"view\", \"file\", \"stream\"\n  - asset.format: \"parquet\", \"csv\", \"json\", \"avro\"\n  - schema.columns: array of column objects\n  - lineage.upstream: array of upstream sources\n  - quality.completeness: 0-1 float (% non-null)\n  - governance.data_classification: \"Public\", \"Internal\", \"Confidential\", \"PII\"\n\n## 3. Authentication\n- How to get Cognito JWT:\n  1. Create service account in BrightHive console\n  2. Get client_id, client_secret\n  3. Call Cognito token endpoint: `POST https://cognito-idp.us-west-2.amazonaws.com/`\n  4. Include JWT in GraphQL request: `Authorization: Bearer <token>`\n- Example:\n```python\nimport requests\n\n# Get JWT from Cognito\nresponse = requests.post(\n    \"https://cognito-idp.us-west-2.amazonaws.com/\",\n    json={\n        \"AuthFlow\": \"USER_PASSWORD_AUTH\",\n        \"ClientId\": \"abc123\",\n        \"AuthParameters\": {\n            \"USERNAME\": \"service-account\",\n            \"PASSWORD\": \"secret\"\n        }\n    }\n)\njwt = response.json()[\"AuthenticationResult\"][\"IdToken\"]\n\n# Call GraphQL API\nheaders = {\"Authorization\": f\"Bearer {jwt}\"}\nresponse = requests.post(\n    \"https://api.brighthive.io/graphql\",\n    headers=headers,\n    json={\"query\": \"...\", \"variables\": {...}}\n)\n```\n\n## 4. Example Implementations\n\n### Example 1: Glue Connector (Python)\n```python\n# See file: brighthive-data-organization-cdk/glue_crawler_lambda/crawler_run/crawler_lambda.py\n# Fetches metadata from Glue GetTable API, pushes to GraphQL\n```\n\n### Example 2: Custom Connector (TypeScript)\n```typescript\nimport { GraphQLClient } from 'graphql-request';\n\nconst client = new GraphQLClient('https://api.brighthive.io/graphql', {\n  headers: { Authorization: `Bearer ${jwt}` }\n});\n\nconst mutation = `\n  mutation createDataAssetWithContext($input: DataAssetContextInput!) {\n    createDataAssetWithContext(input: $input) {\n      uuid name\n    }\n  }\n`;\n\nconst variables = {\n  input: {\n    version: \"v1\",\n    organization_id: \"org-123\",\n    workspace_id: \"ws-456\",\n    asset: { name: \"customers\", type: \"table\", location: \"s3://...\" },\n    schema: { version: \"v1\", columns: [...] }\n  }\n};\n\nconst result = await client.request(mutation, variables);\n```\n\n## 5. Testing Guide\n- Validate payload: Use JSON schema validator\n- Test against staging: `https://staging-api.brighthive.io/graphql`\n- Verify in Neo4j: Query for created DataAsset node\n- Check audit logs: Ensure ASSET_ADDED event emitted\n\n## 6. Troubleshooting\n- **Error: Authentication failed**: Check JWT expiration, client_id, client_secret\n- **Error: Invalid schema**: Validate JSON against schema, check required fields\n- **Error: Missing fields**: Ensure asset.name, asset.type, asset.location provided\n- **Error: GraphQL error**: Check mutation syntax, variable types\n- **Performance**: Use batching for multiple assets (future enhancement)\n\n**File location:**\n- `/Users/bado/iccha/brighthive/docs/connector-developer-guide.md` (new)\n\n**Code examples:**\n- Python: Glue connector (existing code)\n- TypeScript: Custom connector (new example)"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Connector developer guide enables partners and customers to build custom connectors, expanding BrightHive ecosystem. Reduces support burden, accelerates integrations."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Low | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026) - Defer to Sprint 2, documentation can follow implementation"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:26.114-0600",
    "updated": "2026-01-15T14:03:35.066-0600",
    "priority": "Low",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-164",
    "summary": "Design Enterprise Context Configuration View",
    "status": "To Do",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design admin UI for workspace-level context configuration (quality rules, governance policies, lineage capture settings, master data designation)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Create configuration UI mockup. Design settings structure (quality thresholds, compliance frameworks, lineage toggles). Document DynamoDB WorkspaceConfig table. Design GraphQL mutations for config updates."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of configuration UI (Sprint 2). IAM integration for admin access control. Configuration versioning/history."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Frontend, Backend"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Configuration UI mockup: settings page with sections (Quality Rules, Governance Policies, Lineage Capture, Master Data)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Settings structure: min quality score, completeness threshold, freshness SLA, default classification, compliance frameworks, enable DBT/Glue/Redshift lineage, master dataset designation"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 DynamoDB WorkspaceConfig table: workspace_id (PK), config JSON blob"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 GraphQL mutations: updateWorkspaceConfig(workspace_id, config), getWorkspaceConfig(workspace_id)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Validation: ensure thresholds are valid (0-1 float), compliance frameworks from enum"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Audit: log all config changes to AuditLogs table"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: UX Designer, Platform Engineer, Compliance Team"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Configuration UI mockup:**\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Workspace Configuration                         [Save]      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Data Quality Rules                                          \u2502\n\u2502 \u251c\u2500 Minimum quality score: [0.80]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 \u251c\u2500 Completeness threshold: [0.90]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502 \u2514\u2500 Freshness SLA: [24] hours                                \u2502\n\u2502                                                              \u2502\n\u2502 Governance Policies                                         \u2502\n\u2502 \u251c\u2500 Default data classification: [Internal\u25bc]                 \u2502\n\u2502 \u251c\u2500 Compliance frameworks: \u2611 GDPR \u2611 HIPAA \u2610 SOC2            \u2502\n\u2502 \u2514\u2500 Access approval required: \u2611 Yes \u2610 No                     \u2502\n\u2502                                                              \u2502\n\u2502 Lineage Capture                                             \u2502\n\u2502 \u251c\u2500 Enable DBT lineage: \u2611 Yes \u2610 No                           \u2502\n\u2502 \u251c\u2500 Enable Glue lineage: \u2611 Yes \u2610 No                          \u2502\n\u2502 \u2514\u2500 Enable Redshift lineage: \u2611 Yes \u2610 No (experimental)       \u2502\n\u2502                                                              \u2502\n\u2502 Master Data                                                  \u2502\n\u2502 \u251c\u2500 Designated master datasets: [org_a.customers] [+ Add]    \u2502\n\u2502 \u2514\u2500 Master data sync frequency: [Daily\u25bc]                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**DynamoDB WorkspaceConfig table:**\n```python\n{\n    \"workspace_id\": \"ws-123\",  # Partition key\n    \"config\": {\n        \"quality_rules\": {\n            \"min_quality_score\": 0.80,\n            \"completeness_threshold\": 0.90,\n            \"freshness_sla_hours\": 24\n        },\n        \"governance_policies\": {\n            \"default_data_classification\": \"Internal\",\n            \"compliance_frameworks\": [\"GDPR\", \"HIPAA\"],\n            \"access_approval_required\": true\n        },\n        \"lineage_capture\": {\n            \"enable_dbt\": true,\n            \"enable_glue\": true,\n            \"enable_redshift\": false\n        },\n        \"master_data\": {\n            \"designated_master_datasets\": [\"asset-abc-123\"],\n            \"sync_frequency\": \"daily\"\n        }\n    },\n    \"last_updated\": 1705334400000,\n    \"updated_by\": \"admin@brighthive.io\"\n}\n```\n\n**GraphQL mutations:**\n```graphql\nmutation updateWorkspaceConfig(\n  $workspace_id: ID!,\n  $config: WorkspaceConfigInput!\n) {\n  updateWorkspaceConfig(workspace_id: $workspace_id, config: $config) {\n    workspace_id\n    config\n    last_updated\n  }\n}\n\nquery getWorkspaceConfig($workspace_id: ID!) {\n  workspaceConfig(workspace_id: $workspace_id) {\n    workspace_id\n    config\n    last_updated\n    updated_by\n  }\n}\n```\n\n**Validation rules:**\n- min_quality_score: 0.0 \u2264 value \u2264 1.0\n- completeness_threshold: 0.0 \u2264 value \u2264 1.0\n- freshness_sla_hours: positive integer\n- default_data_classification: enum (Public, Internal, Confidential, PII)\n- compliance_frameworks: array of enum (GDPR, HIPAA, SOC2, CCPA)\n\n**Audit logging:**\n- Emit CONFIG_CHANGED event to DynamoDB AuditLogs\n- Include: old config, new config, changed_by, timestamp\n\n**Implementation files:**\n- Frontend: `/Users/bado/iccha/brighthive/brighthive-webapp/src/WorkspaceConfiguration/ContextConfiguration/` (new)\n- Backend resolver: `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/resolvers/workspace-config.ts` (new)\n- DynamoDB table: Create via CDK in platform-core stack"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Workspace configuration enables admins to enforce quality standards, compliance policies, and lineage tracking. Centralized configuration reduces manual effort and ensures consistency across organization."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Low | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026) - Defer to Sprint 2 if needed"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:22.560-0600",
    "updated": "2026-01-16T09:13:14.880-0600",
    "priority": "Low",
    "assignee": "Marwan Samih",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  },
  {
    "key": "BH-158",
    "summary": "Design Context Diff Algorithm",
    "status": "Needs Refinement",
    "type": "Task",
    "description": {
      "type": "doc",
      "version": 1,
      "content": [
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcdd Description"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Compare two context snapshots and show what changed (added/removed/modified assets, lineage changes)."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfaf Type of Issue"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Design Task"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udccd Scope"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Include: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Design context diff algorithm for comparing snapshots. Document diff output format (added_assets, removed_assets, modified_assets, added_lineage, broken_lineage). Create diff visualization design (JSON report, potential UI)."
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Exclude: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Implementation of diff algorithm (Sprint 2). UI for diff visualization (Epic BH-114). Automated diff on every snapshot."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83c\udfd7\ufe0f Areas"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Backend"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\u2705 Acceptance Criteria"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Context diff algorithm designed: compare two ContextSnapshot nodes, return structured diff"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Diff output format: added_assets, removed_assets, modified_assets (with change details), added_lineage, broken_lineage"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Change detection logic: hash comparison for DataAsset properties, edge diff for lineage"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 JSON report format designed for programmatic consumption"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 UI visualization mockup (optional): side-by-side comparison, highlight changes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\u2610 Performance consideration: O(n) time complexity using hash maps"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udc65 Contact"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Owner: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "@drchinca"
            },
            {
              "type": "text",
              "text": " | Stakeholders: Data Engineer"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udd27 Technical Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "**Context diff algorithm:**\n```python\ndef diff_context(snapshot_a: ContextSnapshot, snapshot_b: ContextSnapshot):\n    # Load assets from both snapshots\n    assets_a = fetch_snapshot_assets(snapshot_a.snapshot_id)\n    assets_b = fetch_snapshot_assets(snapshot_b.snapshot_id)\n\n    # Build hash maps for O(1) lookups\n    map_a = {asset.uuid: asset for asset in assets_a}\n    map_b = {asset.uuid: asset for asset in assets_b}\n\n    # Added assets (in B, not in A)\n    added_assets = [asset for uuid, asset in map_b.items() if uuid not in map_a]\n\n    # Removed assets (in A, not in B)\n    removed_assets = [asset for uuid, asset in map_a.items() if uuid not in map_b]\n\n    # Modified assets (in both, but properties changed)\n    modified_assets = []\n    for uuid in set(map_a.keys()) & set(map_b.keys()):\n        asset_a = map_a[uuid]\n        asset_b = map_b[uuid]\n        changes = {}\n        if asset_a.schema_version != asset_b.schema_version:\n            changes['schema'] = f\"{asset_a.schema_version} -> {asset_b.schema_version}\"\n        if asset_a.row_count != asset_b.row_count:\n            changes['row_count'] = f\"{asset_a.row_count} -> {asset_b.row_count}\"\n        if asset_a.quality_score != asset_b.quality_score:\n            changes['quality_score'] = f\"{asset_a.quality_score} -> {asset_b.quality_score}\"\n        if changes:\n            modified_assets.append({\"asset_id\": uuid, \"changes\": changes})\n\n    # Lineage changes\n    lineage_a = fetch_snapshot_lineage(snapshot_a.snapshot_id)\n    lineage_b = fetch_snapshot_lineage(snapshot_b.snapshot_id)\n    added_lineage = [edge for edge in lineage_b if edge not in lineage_a]\n    broken_lineage = [edge for edge in lineage_a if edge not in lineage_b]\n\n    return {\n        \"added_assets\": added_assets,\n        \"removed_assets\": removed_assets,\n        \"modified_assets\": modified_assets,\n        \"added_lineage\": added_lineage,\n        \"broken_lineage\": broken_lineage\n    }\n```\n\n**Output format:**\n```json\n{\n  \"snapshot_a\": \"v2026-01-01\",\n  \"snapshot_b\": \"v2026-01-15\",\n  \"added_assets\": [\n    {\"uuid\": \"asset-123\", \"name\": \"org_c.customers\", \"created_at\": \"2026-01-10\"}\n  ],\n  \"removed_assets\": [\n    {\"uuid\": \"asset-456\", \"name\": \"org_a.temp_table\"}\n  ],\n  \"modified_assets\": [\n    {\n      \"asset_id\": \"asset-789\",\n      \"changes\": {\n        \"schema\": \"v2.1 -> v2.2\",\n        \"row_count\": \"1000000 -> 1200000\",\n        \"quality_score\": \"0.9 -> 0.85\"\n      }\n    }\n  ],\n  \"added_lineage\": [\n    {\"source\": \"asset-123\", \"target\": \"asset-789\", \"type\": \"DERIVED_FROM\"}\n  ],\n  \"broken_lineage\": [\n    {\"source\": \"asset-456\", \"target\": \"asset-789\", \"type\": \"DERIVED_FROM\"}\n  ]\n}\n```\n\n**Use cases:**\n- Answer: \"What changed in the data catalog this week?\"\n- Debugging: \"Why did this dashboard break?\" (compare context before/after)\n- Audit: \"Who changed the schema?\" (context diff + audit logs)"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "\n\n**Files to create:**\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/service/context-diff.ts` - Context diff service\n- `/Users/bado/iccha/brighthive/brighthive-platform-core/src/graphql/resolvers/context-snapshot.ts` - Snapshot resolvers with diff query"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcbc Business Notes"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Context diff enables change tracking, debugging broken pipelines, and auditing metadata changes. Data engineers can quickly understand what changed between versions."
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcca Priority & Timeline"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "Priority: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Low | "
            },
            {
              "type": "text",
              "text": "Timeline: ",
              "marks": [
                {
                  "type": "strong"
                }
              ]
            },
            {
              "type": "text",
              "text": "Week 3 (Jan 27-31, 2026) - Defer to Sprint 2 if needed"
            }
          ]
        },
        {
          "type": "heading",
          "attrs": {
            "level": 3
          },
          "content": [
            {
              "type": "text",
              "text": "\ud83d\udcc5 Milestone"
            }
          ]
        },
        {
          "type": "paragraph",
          "content": [
            {
              "type": "text",
              "text": "M1 - End of January / Sprint 1"
            }
          ]
        }
      ]
    },
    "created": "2026-01-12T16:37:15.346-0600",
    "updated": "2026-01-15T09:59:09.083-0600",
    "priority": "Low",
    "assignee": "Hikuri Chinca",
    "labels": [
      "M1",
      "data-lake-context",
      "sprint-1"
    ]
  }
]